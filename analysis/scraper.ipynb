{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b43504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x5c43sa7u6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mm7udaen1m",
   "metadata": {},
   "source": [
    "# Riot API Scraper for NattyNatt Rengar Analysis\n",
    "\n",
    "This notebook scrapes League of Legends match data from the Riot API for detailed gameplay analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e474c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"RIOT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"RIOT_API_KEY not found in .env file\")\n",
    "\n",
    "SUMMONER_NAME = \"NattyNatt\"\n",
    "SUMMONER_TAG = \"RANK1\"\n",
    "REGION = \"kr\"\n",
    "ROUTING_REGION = \"asia\"\n",
    "\n",
    "BASE_URL_SUMMONER = f\"https://{REGION}.api.riotgames.com\"\n",
    "BASE_URL_MATCH = f\"https://{ROUTING_REGION}.api.riotgames.com\"\n",
    "BASE_URL_ACCOUNT = f\"https://{ROUTING_REGION}.api.riotgames.com\"\n",
    "\n",
    "RATE_LIMIT_PER_1_SEC = 20\n",
    "RATE_LIMIT_PER_2_MIN = 100\n",
    "request_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awxiwo4fg3d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Load API credentials and set up rate limiting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_limit_check():\n",
    "    current_time = time.time()\n",
    "    \n",
    "    request_times[:] = [t for t in request_times if current_time - t < 120]\n",
    "    \n",
    "    requests_last_second = [t for t in request_times if current_time - t < 1]\n",
    "    if len(requests_last_second) >= RATE_LIMIT_PER_1_SEC:\n",
    "        oldest_in_window = requests_last_second[0]\n",
    "        sleep_time = 1.01 - (current_time - oldest_in_window)\n",
    "        if sleep_time > 0:\n",
    "            print(f\"1-second rate limit reached ({len(requests_last_second)}/20). Sleeping for {sleep_time:.2f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            current_time = time.time()\n",
    "            request_times[:] = [t for t in request_times if current_time - t < 120]\n",
    "    \n",
    "    if len(request_times) >= RATE_LIMIT_PER_2_MIN:\n",
    "        oldest_request = request_times[0]\n",
    "        sleep_time = 120.01 - (current_time - oldest_request)\n",
    "        if sleep_time > 0:\n",
    "            print(f\"2-minute rate limit reached ({len(request_times)}/100). Sleeping for {sleep_time:.1f} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "            current_time = time.time()\n",
    "            request_times[:] = [t for t in request_times if current_time - t < 120]\n",
    "    \n",
    "    request_times.append(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lj26m8w6wk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_details(match_id: str) -> Optional[Dict]:\n",
    "    url = f\"{BASE_URL_MATCH}/lol/match/v5/matches/{match_id}\"\n",
    "    headers = {\"X-Riot-Token\": API_KEY}\n",
    "    \n",
    "    rate_limit_check()\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    elif response.status_code == 404:\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Error getting match {match_id}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_match_timeline(match_id: str) -> Optional[Dict]:\n",
    "    url = f\"{BASE_URL_MATCH}/lol/match/v5/matches/{match_id}/timeline\"\n",
    "    headers = {\"X-Riot-Token\": API_KEY}\n",
    "    \n",
    "    rate_limit_check()\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    elif response.status_code == 404:\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Error getting timeline {match_id}: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ho8ejkbiqj8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gank_timings(timeline: Dict, participant_id: int, max_time: int = 300) -> Dict:\n",
    "    frames = timeline.get(\"info\", {}).get(\"frames\", [])\n",
    "    \n",
    "    gank_times = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        timestamp = frame.get(\"timestamp\", 0) / 1000\n",
    "        if timestamp > max_time:\n",
    "            break\n",
    "            \n",
    "        events = frame.get(\"events\", [])\n",
    "        for event in events:\n",
    "            if event.get(\"type\") == \"CHAMPION_KILL\":\n",
    "                if event.get(\"killerId\") == participant_id or participant_id in event.get(\"assistingParticipantIds\", []):\n",
    "                    gank_times.append(timestamp)\n",
    "    \n",
    "    first_gank_time = gank_times[0] if gank_times else None\n",
    "    \n",
    "    return {\n",
    "        \"first_gank_time\": first_gank_time,\n",
    "        \"ganks_by_5min\": len([t for t in gank_times if t <= 300])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45iuppp9691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skill_order(timeline: Dict, participant_id: int) -> Dict:\n",
    "    frames = timeline.get(\"info\", {}).get(\"frames\", [])\n",
    "    \n",
    "    skill_order = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        events = frame.get(\"events\", [])\n",
    "        \n",
    "        for event in events:\n",
    "            if event.get(\"type\") == \"SKILL_LEVEL_UP\":\n",
    "                if event.get(\"participantId\") == participant_id:\n",
    "                    skill_slot = event.get(\"skillSlot\")\n",
    "                    skill_map = {1: \"Q\", 2: \"W\", 3: \"E\", 4: \"R\"}\n",
    "                    skill = skill_map.get(skill_slot, str(skill_slot))\n",
    "                    skill_order.append(skill)\n",
    "    \n",
    "    skill_counts = {\"Q\": 0, \"W\": 0, \"E\": 0}\n",
    "    max_order = []\n",
    "    \n",
    "    for skill in skill_order[:9]:\n",
    "        if skill in skill_counts:\n",
    "            skill_counts[skill] += 1\n",
    "            if skill_counts[skill] == 5 and skill not in max_order:\n",
    "                max_order.append(skill)\n",
    "    \n",
    "    return {\n",
    "        \"skill_order\": \"->\".join(skill_order[:18]) if skill_order else None,\n",
    "        \"max_order\": \"->\".join(max_order) if max_order else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8xkmc29scuy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_item_timeline(timeline: Dict, participant_id: int) -> Dict:\n",
    "    frames = timeline.get(\"info\", {}).get(\"frames\", [])\n",
    "    \n",
    "    item_purchases = []\n",
    "    control_wards_bought = 0\n",
    "    \n",
    "    for frame in frames:\n",
    "        timestamp = frame.get(\"timestamp\", 0) / 1000\n",
    "        events = frame.get(\"events\", [])\n",
    "        \n",
    "        for event in events:\n",
    "            if event.get(\"type\") == \"ITEM_PURCHASED\" and event.get(\"participantId\") == participant_id:\n",
    "                item_id = event.get(\"itemId\")\n",
    "                item_purchases.append(f\"{item_id}@{int(timestamp)}s\")\n",
    "                \n",
    "                if item_id == 2055:\n",
    "                    control_wards_bought += 1\n",
    "    \n",
    "    build_order = \"->\".join(item_purchases[:15]) if item_purchases else None\n",
    "    \n",
    "    mythic_time = None\n",
    "    mythic_ids = {6630, 6631, 6632, 6653, 6655, 6656, 6662, 6664, 6665, 6671, 6672, 6673, 6691, 6692, 6693}\n",
    "    for purchase in item_purchases:\n",
    "        item_info = purchase.split(\"@\")\n",
    "        if int(item_info[0]) in mythic_ids:\n",
    "            mythic_time = item_info[1]\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"item_build_order\": build_order,\n",
    "        \"mythic_completion_time\": mythic_time,\n",
    "        \"control_wards_bought\": control_wards_bought,\n",
    "        \"total_items_purchased\": len(item_purchases)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k3kgwgy0ppo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_runes_and_spells(participant: Dict) -> Dict:\n",
    "    perks = participant.get(\"perks\", {})\n",
    "    styles = perks.get(\"styles\", [])\n",
    "    \n",
    "    primary_style = styles[0] if len(styles) > 0 else {}\n",
    "    secondary_style = styles[1] if len(styles) > 1 else {}\n",
    "    \n",
    "    primary_selections = primary_style.get(\"selections\", [])\n",
    "    secondary_selections = secondary_style.get(\"selections\", [])\n",
    "    \n",
    "    stat_perks = perks.get(\"statPerks\", {})\n",
    "    \n",
    "    return {\n",
    "        \"primary_tree\": primary_style.get(\"style\"),\n",
    "        \"keystone\": primary_selections[0].get(\"perk\") if len(primary_selections) > 0 else None,\n",
    "        \"rune_1\": primary_selections[1].get(\"perk\") if len(primary_selections) > 1 else None,\n",
    "        \"rune_2\": primary_selections[2].get(\"perk\") if len(primary_selections) > 2 else None,\n",
    "        \"rune_3\": primary_selections[3].get(\"perk\") if len(primary_selections) > 3 else None,\n",
    "        \"secondary_tree\": secondary_style.get(\"style\"),\n",
    "        \"rune_4\": secondary_selections[0].get(\"perk\") if len(secondary_selections) > 0 else None,\n",
    "        \"rune_5\": secondary_selections[1].get(\"perk\") if len(secondary_selections) > 1 else None,\n",
    "        \"stat_shard_1\": stat_perks.get(\"defense\"),\n",
    "        \"stat_shard_2\": stat_perks.get(\"flex\"),\n",
    "        \"stat_shard_3\": stat_perks.get(\"offense\"),\n",
    "        \"summoner_1\": participant.get(\"summoner1Id\"),\n",
    "        \"summoner_2\": participant.get(\"summoner2Id\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mot79oh89lb",
   "metadata": {},
   "source": [
    "## Build and Runes Extraction\n",
    "\n",
    "Functions to extract runes, summoner spells, item builds, and skill orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nzvps46akt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_camp_sequence(timeline: Dict, participant_id: int, max_time: int = 300) -> Dict:\n",
    "    frames = timeline.get(\"info\", {}).get(\"frames\", [])\n",
    "    \n",
    "    camp_kills = []\n",
    "    monster_types = {\n",
    "        \"SRU_Baron\": \"BARON\",\n",
    "        \"SRU_Dragon\": \"DRAGON\",\n",
    "        \"SRU_RiftHerald\": \"HERALD\",\n",
    "        \"SRU_Red\": \"RED_BUFF\",\n",
    "        \"SRU_Blue\": \"BLUE_BUFF\",\n",
    "        \"SRU_Gromp\": \"GROMP\",\n",
    "        \"SRU_Murkwolf\": \"WOLVES\",\n",
    "        \"SRU_Razorbeak\": \"RAPTORS\",\n",
    "        \"SRU_Krug\": \"KRUGS\",\n",
    "        \"SRU_Crab\": \"SCUTTLE\"\n",
    "    }\n",
    "    \n",
    "    for frame in frames:\n",
    "        timestamp = frame.get(\"timestamp\", 0) / 1000\n",
    "        if timestamp > max_time:\n",
    "            break\n",
    "            \n",
    "        events = frame.get(\"events\", [])\n",
    "        for event in events:\n",
    "            if event.get(\"type\") == \"MONSTER_KILL\":\n",
    "                if event.get(\"killerId\") == participant_id:\n",
    "                    monster_type = event.get(\"monsterType\", \"\")\n",
    "                    monster_subtype = event.get(\"monsterSubType\", \"\")\n",
    "                    \n",
    "                    camp_name = None\n",
    "                    if monster_type in monster_types:\n",
    "                        camp_name = monster_types[monster_type]\n",
    "                    elif monster_subtype in monster_types:\n",
    "                        camp_name = monster_types[monster_subtype]\n",
    "                    \n",
    "                    if camp_name:\n",
    "                        camp_kills.append({\n",
    "                            \"camp\": camp_name,\n",
    "                            \"timestamp\": timestamp\n",
    "                        })\n",
    "    \n",
    "    camp_kills.sort(key=lambda x: x[\"timestamp\"])\n",
    "    \n",
    "    camp_sequence = \"->\".join([c[\"camp\"] for c in camp_kills])\n",
    "    first_camp = camp_kills[0][\"camp\"] if camp_kills else None\n",
    "    first_camp_time = camp_kills[0][\"timestamp\"] if camp_kills else None\n",
    "    \n",
    "    camps_by_5min = len([c for c in camp_kills if c[\"timestamp\"] <= 300])\n",
    "    \n",
    "    scuttle_kills = [c for c in camp_kills if c[\"camp\"] == \"SCUTTLE\"]\n",
    "    first_scuttle_time = scuttle_kills[0][\"timestamp\"] if scuttle_kills else None\n",
    "    \n",
    "    return {\n",
    "        \"camp_sequence\": camp_sequence,\n",
    "        \"first_camp\": first_camp,\n",
    "        \"first_camp_time\": first_camp_time,\n",
    "        \"camps_cleared_by_5min\": camps_by_5min,\n",
    "        \"first_scuttle_time\": first_scuttle_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x7t0agjyhc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cs_at_minutes(timeline: Dict, participant_id: int, minutes: List[int] = [1,2,3,4,5]) -> Dict:\n",
    "    frames = timeline.get(\"info\", {}).get(\"frames\", [])\n",
    "    cs_data = {}\n",
    "    \n",
    "    for minute in minutes:\n",
    "        frame_index = minute\n",
    "        if frame_index < len(frames):\n",
    "            frame = frames[frame_index]\n",
    "            participant_frame = frame.get(\"participantFrames\", {}).get(str(participant_id), {})\n",
    "            cs_data[f\"cs_at_{minute}min\"] = participant_frame.get(\"minionsKilled\", 0) + \\\n",
    "                                            participant_frame.get(\"jungleMinionsKilled\", 0)\n",
    "        else:\n",
    "            cs_data[f\"cs_at_{minute}min\"] = None\n",
    "    \n",
    "    return cs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92hy5j5fgru",
   "metadata": {},
   "source": [
    "## Jungle-Specific Extraction Functions\n",
    "\n",
    "Functions to extract jungle camp sequences, CS progression, and gank timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9xg04e0ipeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_ids(puuid: str, count: int = 100, queue_id: int = None, start_time: int = None) -> List[str]:\n",
    "    all_match_ids = []\n",
    "    start_index = 0\n",
    "    batch_size = 100\n",
    "    \n",
    "    while True:\n",
    "        url = f\"{BASE_URL_MATCH}/lol/match/v5/matches/by-puuid/{puuid}/ids\"\n",
    "        params = {\"start\": start_index, \"count\": batch_size}\n",
    "        if queue_id:\n",
    "            params[\"queue\"] = queue_id\n",
    "        if start_time:\n",
    "            params[\"startTime\"] = start_time\n",
    "        \n",
    "        headers = {\"X-Riot-Token\": API_KEY}\n",
    "        \n",
    "        rate_limit_check()\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            match_ids = response.json()\n",
    "            if not match_ids:\n",
    "                break\n",
    "            \n",
    "            all_match_ids.extend(match_ids)\n",
    "            print(f\"  Fetched {len(match_ids)} match IDs (total: {len(all_match_ids)})\")\n",
    "            \n",
    "            if len(match_ids) < batch_size:\n",
    "                break\n",
    "            \n",
    "            if count and len(all_match_ids) >= count:\n",
    "                all_match_ids = all_match_ids[:count]\n",
    "                break\n",
    "            \n",
    "            start_index += batch_size\n",
    "        else:\n",
    "            print(f\"Error getting match IDs: {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    return all_match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4h0ghawrh3m",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summoner_puuid(game_name: str, tag_line: str = None) -> Optional[str]:\n",
    "    import urllib.parse\n",
    "    \n",
    "    if not tag_line:\n",
    "        print(\"Tag line is required for Account-V1 API\")\n",
    "        return None\n",
    "    \n",
    "    encoded_game_name = urllib.parse.quote(game_name)\n",
    "    encoded_tag = urllib.parse.quote(tag_line)\n",
    "    url = f\"{BASE_URL_ACCOUNT}/riot/account/v1/accounts/by-riot-id/{encoded_game_name}/{encoded_tag}\"\n",
    "    headers = {\"X-Riot-Token\": API_KEY}\n",
    "    \n",
    "    rate_limit_check()\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        puuid = data.get(\"puuid\")\n",
    "        print(f\"✓ Found PUUID: {puuid[:8]}...\")\n",
    "        return puuid\n",
    "    else:\n",
    "        print(f\"Error getting PUUID: {response.status_code}\")\n",
    "        try:\n",
    "            error_data = response.json()\n",
    "            print(f\"Error details: {error_data}\")\n",
    "        except:\n",
    "            print(f\"Response text: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jxztyzmp3il",
   "metadata": {},
   "source": [
    "## Core API Functions\n",
    "\n",
    "Functions to fetch player PUUID, match IDs, match details, and timelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849l1geqc5l",
   "metadata": {},
   "source": [
    "## Rate Limiting\n",
    "\n",
    "Manages API rate limits: 20 requests per second and 100 requests per 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d8999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MAIN SCRAPER - Fetch All Matches with Comprehensive Data\n",
      "================================================================================\n",
      "\n",
      "✓ Match data already exists: data/nattynatt_rengar_matches.csv\n",
      "  - 317 matches found\n",
      "  - Columns: 117\n",
      "\n",
      "Skipping scraper. Delete the file to re-scrape.\n",
      "Or set FORCE_RESCRAPE = True below to overwrite.\n",
      "\n",
      "✓ Using existing data. Proceed to Cell 4 for frame extraction!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"MAIN SCRAPER - Fetch All Matches with Comprehensive Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "csv_path = \"data/nattynatt_rengar_matches.csv\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    existing_df = pd.read_csv(csv_path)\n",
    "    print(f\"\\n✓ Match data already exists: {csv_path}\")\n",
    "    print(f\"  - {len(existing_df)} matches found\")\n",
    "    print(f\"  - Columns: {len(existing_df.columns)}\")\n",
    "    print(\"\\nSkipping scraper. Delete the file to re-scrape.\")\n",
    "    print(\"Or set FORCE_RESCRAPE = True below to overwrite.\\n\")\n",
    "    \n",
    "    FORCE_RESCRAPE = False\n",
    "    \n",
    "    if not FORCE_RESCRAPE:\n",
    "        print(\"✓ Using existing data. Proceed to Cell 4 for frame extraction!\")\n",
    "    else:\n",
    "        print(\"⚠️  FORCE_RESCRAPE = True - Re-scraping all matches...\")\n",
    "        df = scrape_all_matches(SUMMONER_NAME, SUMMONER_TAG, months_back=4)\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n✓ Re-scraped and saved {len(df)} matches to {csv_path}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No existing data found. Starting scraper...\")\n",
    "    print(\"\\nThis will scrape all matches from the last 4 months with:\")\n",
    "    print(\"  - Basic stats (KDA, CS, gold, damage)\")\n",
    "    print(\"  - Runes and summoner spells\")  \n",
    "    print(\"  - Item build timeline\")\n",
    "    print(\"  - Frame progression (gold/xp at 5/10/15/20 min)\")\n",
    "    print(\"  - Objectives (dragons, herald, baron, turrets)\")\n",
    "    print(\"  - Vision control\")\n",
    "    print(\"  - Positioning and pathing\")\n",
    "    print(\"  - Skill order\")\n",
    "    print(\"  - Combat stats\")\n",
    "    print(\"  - Team composition and matchups\")\n",
    "    print(\"\\n⚠️  This will take a while and use API rate limits!\\n\")\n",
    "    \n",
    "    df = scrape_all_matches(SUMMONER_NAME, SUMMONER_TAG, months_back=4)\n",
    "    \n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    \n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n✓ Saved {len(df)} matches to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831a3ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing new extraction functions on a single match...\n",
      "✓ Found PUUID: DefvgEBJ...\n",
      "Fetching a test match...\n",
      "  Fetched 100 match IDs (total: 100)\n",
      "Testing with match: KR_7907383471\n",
      "\n",
      "✓ Successfully extracted 117 fields!\n",
      "\n",
      "Sample of new fields:\n",
      "  - Primary tree: 8000\n",
      "  - Keystone: 8010\n",
      "  - Summoners: 4, 11\n",
      "  - Gold at 10min: 4403\n",
      "  - Level at 10min: 7\n",
      "  - Dragons killed: 1\n",
      "  - Wards placed: 3\n",
      "  - Kill participation: 65.0%\n",
      "  - Enemy jungle: Elise\n",
      "  - Ally top: Olaf\n",
      "  - Skill order: Q->W->E->Q->Q->R->Q->E->Q->E->R...\n",
      "  - Item build: 1102@60s->3340@60s->2003@60s->1036@240s->1036@240s->3134@420s->6690@420s->3364@4...\n",
      "\n",
      "✓ All extraction functions working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test extraction on a single match to verify all functions work\n",
    "print(\"Testing new extraction functions on a single match...\")\n",
    "\n",
    "# Get PUUID\n",
    "puuid = get_summoner_puuid(SUMMONER_NAME, SUMMONER_TAG)\n",
    "\n",
    "if puuid:\n",
    "    # Get first match\n",
    "    print(\"Fetching a test match...\")\n",
    "    match_ids = get_match_ids(puuid, count=1, queue_id=420, start_time=None)\n",
    "    \n",
    "    if match_ids:\n",
    "        test_match_id = match_ids[0]\n",
    "        print(f\"Testing with match: {test_match_id}\")\n",
    "        \n",
    "        # Process the match\n",
    "        match_result = process_match(test_match_id, puuid)\n",
    "        \n",
    "        if match_result:\n",
    "            print(f\"\\n✓ Successfully extracted {len(match_result)} fields!\")\n",
    "            print(\"\\nSample of new fields:\")\n",
    "            print(f\"  - Primary tree: {match_result.get('primary_tree')}\")\n",
    "            print(f\"  - Keystone: {match_result.get('keystone')}\")\n",
    "            print(f\"  - Summoners: {match_result.get('summoner_1')}, {match_result.get('summoner_2')}\")\n",
    "            print(f\"  - Gold at 10min: {match_result.get('gold_at_10min')}\")\n",
    "            print(f\"  - Level at 10min: {match_result.get('level_at_10min')}\")\n",
    "            print(f\"  - Dragons killed: {match_result.get('dragons_killed')}\")\n",
    "            print(f\"  - Wards placed: {match_result.get('wards_placed')}\")\n",
    "            print(f\"  - Kill participation: {match_result.get('kill_participation_pct')}%\")\n",
    "            print(f\"  - Enemy jungle: {match_result.get('enemy_jungle')}\")\n",
    "            print(f\"  - Ally top: {match_result.get('ally_top')}\")\n",
    "            print(f\"  - Skill order: {match_result.get('skill_order')[:50]}...\" if match_result.get('skill_order') else \"  - Skill order: None\")\n",
    "            print(f\"  - Item build: {match_result.get('item_build_order')[:80]}...\" if match_result.get('item_build_order') else \"  - Item build: None\")\n",
    "            print(\"\\n✓ All extraction functions working correctly!\")\n",
    "        else:\n",
    "            print(\"✗ Match processing returned None (might not be a Rengar game)\")\n",
    "    else:\n",
    "        print(\"✗ No matches found\")\n",
    "else:\n",
    "    print(\"✗ Failed to get PUUID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81b3694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FRAME-BY-FRAME DATA EXTRACTION (All 10 Players)\n",
      "================================================================================\n",
      "\n",
      "This extracts minute-by-minute position, gold, XP, CS, and damage data\n",
      "for all 10 players in each match. Use for behavioral analysis and\n",
      "comparing NattyNatt vs enemy jungler pathing.\n",
      "\n",
      "Found 317 matches to process\n",
      "Estimated frames: ~79250 (10 players × 25 min avg)\n",
      "\n",
      "Starting extraction...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Found PUUID: DefvgEBJ...\n",
      "[10/317] Processed: 10 | Frames: 2550 | ETA: 7m 44s\n",
      "[20/317] Processed: 20 | Frames: 4980 | ETA: 7m 32s\n",
      "[30/317] Processed: 30 | Frames: 7230 | ETA: 7m 8s\n",
      "[40/317] Processed: 40 | Frames: 9860 | ETA: 6m 52s\n",
      "2-minute rate limit reached (100/100). Sleeping for 46.3 seconds...\n",
      "Error getting timeline KR_7883625192: 429\n",
      "[48/317] ✗ KR_7883625192: No timeline data\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[50/317] Processed: 49 | Frames: 12200 | ETA: 10m 48s\n",
      "[60/317] Processed: 59 | Frames: 14830 | ETA: 9m 45s\n",
      "[70/317] Processed: 69 | Frames: 17340 | ETA: 8m 53s\n",
      "[80/317] Processed: 79 | Frames: 19730 | ETA: 8m 12s\n",
      "[90/317] Processed: 89 | Frames: 22200 | ETA: 7m 36s\n",
      "2-minute rate limit reached (100/100). Sleeping for 45.7 seconds...\n",
      "[100/317] Processed: 99 | Frames: 24780 | ETA: 8m 44s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[110/317] Processed: 109 | Frames: 27140 | ETA: 8m 3s\n",
      "[120/317] Processed: 119 | Frames: 29770 | ETA: 7m 27s\n",
      "[130/317] Processed: 129 | Frames: 32430 | ETA: 6m 53s\n",
      "[140/317] Processed: 139 | Frames: 35040 | ETA: 6m 22s\n",
      "2-minute rate limit reached (100/100). Sleeping for 43.3 seconds...\n",
      "[150/317] Processed: 149 | Frames: 37760 | ETA: 6m 42s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.4 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[160/317] Processed: 159 | Frames: 40070 | ETA: 6m 10s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[170/317] Processed: 169 | Frames: 42900 | ETA: 5m 39s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[180/317] Processed: 179 | Frames: 45210 | ETA: 5m 10s\n",
      "[190/317] Processed: 189 | Frames: 47650 | ETA: 4m 42s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 43.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[200/317] Processed: 199 | Frames: 50030 | ETA: 4m 41s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[210/317] Processed: 209 | Frames: 52550 | ETA: 4m 13s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[220/317] Processed: 219 | Frames: 55370 | ETA: 3m 46s\n",
      "[230/317] Processed: 229 | Frames: 58150 | ETA: 3m 19s\n",
      "[240/317] Processed: 239 | Frames: 60890 | ETA: 2m 54s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 43.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "Error getting match KR_7790039047: 429\n",
      "[249/317] ✗ KR_7790039047: No match data\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "[250/317] Processed: 248 | Frames: 63210 | ETA: 2m 41s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[260/317] Processed: 258 | Frames: 65630 | ETA: 2m 15s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[270/317] Processed: 268 | Frames: 68220 | ETA: 1m 50s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[280/317] Processed: 278 | Frames: 70860 | ETA: 1m 25s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[290/317] Processed: 288 | Frames: 73530 | ETA: 1m 1s\n",
      "2-minute rate limit reached (100/100). Sleeping for 41.8 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[300/317] Processed: 298 | Frames: 76170 | ETA: 0m 40s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[310/317] Processed: 308 | Frames: 78750 | ETA: 0m 16s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "\n",
      "================================================================================\n",
      "FRAME EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Processed matches: 315/317\n",
      "Errors: 2\n",
      "Total frames extracted: 80,150\n",
      "Unique players tracked: 10\n",
      "Total time: 12m 28s\n",
      "\n",
      "Saved to: data/nattynatt_rengar_frames.csv\n",
      "File size: 8.8 MB\n",
      "\n",
      "Frame data columns:\n",
      "  - 23 columns\n",
      "  - Key fields: position_x/y, gold, xp, level, cs, damage\n",
      "  - Flags: is_nattynatt, is_ally, is_enemy_jungler\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Extract Frame-by-Frame Data for All Players\n",
    "print(\"=\"*80)\n",
    "print(\"FRAME-BY-FRAME DATA EXTRACTION (All 10 Players)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis extracts minute-by-minute position, gold, XP, CS, and damage data\")\n",
    "print(\"for all 10 players in each match. Use for behavioral analysis and\")\n",
    "print(\"comparing NattyNatt vs enemy jungler pathing.\\n\")\n",
    "\n",
    "# Read existing match IDs\n",
    "matches_csv = \"data/nattynatt_rengar_matches.csv\"\n",
    "if not os.path.exists(matches_csv):\n",
    "    print(f\"Error: {matches_csv} not found. Run Cell 2 first to scrape matches.\")\n",
    "else:\n",
    "    matches_df = pd.read_csv(matches_csv)\n",
    "    match_ids_to_process = matches_df['match_id'].tolist()\n",
    "    \n",
    "    print(f\"Found {len(match_ids_to_process)} matches to process\")\n",
    "    print(f\"Estimated frames: ~{len(match_ids_to_process) * 10 * 25} (10 players × 25 min avg)\")\n",
    "    print(\"\\nStarting extraction...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    all_frames = []\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get PUUID for target player\n",
    "    puuid = get_summoner_puuid(SUMMONER_NAME, SUMMONER_TAG)\n",
    "    \n",
    "    if not puuid:\n",
    "        print(\"Error: Could not get PUUID\")\n",
    "    else:\n",
    "        for idx, match_id in enumerate(match_ids_to_process):\n",
    "            try:\n",
    "                # Fetch match data and timeline\n",
    "                match_data = get_match_details(match_id)\n",
    "                if not match_data:\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: No match data\")\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                timeline_data = get_match_timeline(match_id)\n",
    "                if not timeline_data:\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: No timeline data\")\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # Extract frames for all players\n",
    "                frames = extract_all_frames_multi_player(match_data, timeline_data, puuid)\n",
    "                all_frames.extend(frames)\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress update every 10 matches\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    avg_time = elapsed / (idx + 1)\n",
    "                    remaining = avg_time * (len(match_ids_to_process) - idx - 1)\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] Processed: {processed_count} | \"\n",
    "                          f\"Frames: {len(all_frames)} | \"\n",
    "                          f\"ETA: {int(remaining/60)}m {int(remaining%60)}s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: Error - {str(e)}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "        \n",
    "        # Convert to DataFrame and save\n",
    "        if all_frames:\n",
    "            frames_df = pd.DataFrame(all_frames)\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_path = \"data/nattynatt_rengar_frames.csv\"\n",
    "            frames_df.to_csv(output_path, index=False)\n",
    "            \n",
    "            elapsed_total = time.time() - start_time\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"FRAME EXTRACTION COMPLETE\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"Processed matches: {processed_count}/{len(match_ids_to_process)}\")\n",
    "            print(f\"Errors: {error_count}\")\n",
    "            print(f\"Total frames extracted: {len(all_frames):,}\")\n",
    "            print(f\"Unique players tracked: {frames_df['participant_id'].nunique()}\")\n",
    "            print(f\"Total time: {int(elapsed_total/60)}m {int(elapsed_total%60)}s\")\n",
    "            print(f\"\\nSaved to: {output_path}\")\n",
    "            print(f\"File size: {os.path.getsize(output_path) / (1024*1024):.1f} MB\")\n",
    "            print(\"\\nFrame data columns:\")\n",
    "            print(f\"  - {len(frames_df.columns)} columns\")\n",
    "            print(f\"  - Key fields: position_x/y, gold, xp, level, cs, damage\")\n",
    "            print(f\"  - Flags: is_nattynatt, is_ally, is_enemy_jungler\")\n",
    "        else:\n",
    "            print(\"\\nNo frames extracted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeebbcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVENT DATA EXTRACTION (Precise Timestamps)\n",
      "================================================================================\n",
      "\n",
      "This extracts all game events with millisecond precision:\n",
      "  - Jungle camp clears (for pathing reconstruction)\n",
      "  - Champion kills/deaths/assists\n",
      "  - Item purchases and sales\n",
      "  - Ward placements and destructions\n",
      "  - Objective takes (dragons, herald, baron)\n",
      "  - Turret/inhibitor kills\n",
      "\n",
      "Use for second-by-second behavioral analysis.\n",
      "\n",
      "Found 317 matches to process\n",
      "Estimated events: ~95100 (avg 300 events/game)\n",
      "\n",
      "Starting extraction...\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Found PUUID: DefvgEBJ...\n",
      "[10/317] Processed: 10 | Events: 10,047 | ETA: 8m 5s\n",
      "[20/317] Processed: 20 | Events: 19,154 | ETA: 7m 39s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[30/317] Processed: 30 | Events: 27,736 | ETA: 7m 24s\n",
      "2-minute rate limit reached (100/100). Sleeping for 42.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[40/317] Processed: 40 | Events: 37,635 | ETA: 12m 2s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.7 seconds...\n",
      "[50/317] Processed: 50 | Events: 47,183 | ETA: 10m 46s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[60/317] Processed: 60 | Events: 57,249 | ETA: 9m 44s\n",
      "[70/317] Processed: 70 | Events: 66,601 | ETA: 8m 54s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[80/317] Processed: 80 | Events: 75,561 | ETA: 8m 14s\n",
      "2-minute rate limit reached (100/100). Sleeping for 41.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[90/317] Processed: 90 | Events: 84,665 | ETA: 9m 25s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.6 seconds...\n",
      "[100/317] Processed: 100 | Events: 95,162 | ETA: 8m 42s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.4 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[110/317] Processed: 110 | Events: 104,309 | ETA: 8m 2s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[120/317] Processed: 120 | Events: 114,231 | ETA: 7m 26s\n",
      "[130/317] Processed: 130 | Events: 124,112 | ETA: 6m 53s\n",
      "2-minute rate limit reached (100/100). Sleeping for 40.8 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[140/317] Processed: 140 | Events: 134,454 | ETA: 7m 15s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.6 seconds...\n",
      "[150/317] Processed: 150 | Events: 145,297 | ETA: 6m 41s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.5 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[160/317] Processed: 160 | Events: 153,723 | ETA: 6m 9s\n",
      "[170/317] Processed: 170 | Events: 165,350 | ETA: 5m 39s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[180/317] Processed: 180 | Events: 174,426 | ETA: 5m 10s\n",
      "2-minute rate limit reached (100/100). Sleeping for 40.7 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "Error getting timeline KR_7801527474: 429\n",
      "[182/317] ✗ KR_7801527474: No timeline data\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.5 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[190/317] Processed: 189 | Events: 183,180 | ETA: 5m 10s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.6 seconds...\n",
      "[200/317] Processed: 199 | Events: 193,116 | ETA: 4m 41s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[210/317] Processed: 209 | Events: 202,676 | ETA: 4m 13s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[220/317] Processed: 219 | Events: 213,712 | ETA: 3m 46s\n",
      "[230/317] Processed: 229 | Events: 224,886 | ETA: 3m 19s\n",
      "2-minute rate limit reached (100/100). Sleeping for 40.5 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[240/317] Processed: 239 | Events: 236,038 | ETA: 3m 7s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.5 seconds...\n",
      "[250/317] Processed: 249 | Events: 246,581 | ETA: 2m 41s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[260/317] Processed: 259 | Events: 256,802 | ETA: 2m 15s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "[270/317] Processed: 269 | Events: 267,140 | ETA: 1m 50s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[280/317] Processed: 279 | Events: 276,430 | ETA: 1m 25s\n",
      "2-minute rate limit reached (100/100). Sleeping for 40.4 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "Error getting match KR_7784441165: 429\n",
      "[283/317] ✗ KR_7784441165: No match data\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "[290/317] Processed: 288 | Events: 285,451 | ETA: 1m 5s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.4 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[300/317] Processed: 298 | Events: 294,683 | ETA: 0m 40s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.5 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.0 seconds...\n",
      "[310/317] Processed: 308 | Events: 304,233 | ETA: 0m 16s\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.1 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.3 seconds...\n",
      "2-minute rate limit reached (100/100). Sleeping for 0.2 seconds...\n",
      "\n",
      "================================================================================\n",
      "EVENT EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Processed matches: 315/317\n",
      "Errors: 2\n",
      "Total events extracted: 309,101\n",
      "Total time: 12m 29s\n",
      "\n",
      "Saved to: data/nattynatt_rengar_events.csv\n",
      "File size: 25.4 MB\n",
      "\n",
      "Event type breakdown:\n",
      "  - ITEM_PURCHASED: 67,249\n",
      "  - WARD_PLACED: 57,717\n",
      "  - ITEM_DESTROYED: 52,952\n",
      "  - SKILL_LEVEL_UP: 42,225\n",
      "  - LEVEL_UP: 38,630\n",
      "  - CHAMPION_KILL: 15,450\n",
      "  - WARD_KILL: 13,542\n",
      "  - TURRET_PLATE_DESTROYED: 3,741\n",
      "  - FEAT_UPDATE: 3,163\n",
      "  - BUILDING_KILL: 3,012\n",
      "\n",
      "NattyNatt's events: 28,673\n",
      "  - MONSTER_KILL: 0\n",
      "  - CHAMPION_KILL: 3,097\n",
      "  - ITEM_PURCHASED: 6,347\n",
      "  - WARD_PLACED: 1,241\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Extract Event Data with Precise Timestamps\n",
    "print(\"=\"*80)\n",
    "print(\"EVENT DATA EXTRACTION (Precise Timestamps)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis extracts all game events with millisecond precision:\")\n",
    "print(\"  - Jungle camp clears (for pathing reconstruction)\")\n",
    "print(\"  - Champion kills/deaths/assists\")\n",
    "print(\"  - Item purchases and sales\")\n",
    "print(\"  - Ward placements and destructions\")\n",
    "print(\"  - Objective takes (dragons, herald, baron)\")\n",
    "print(\"  - Turret/inhibitor kills\")\n",
    "print(\"\\nUse for second-by-second behavioral analysis.\\n\")\n",
    "\n",
    "# Read existing match IDs\n",
    "matches_csv = \"data/nattynatt_rengar_matches.csv\"\n",
    "if not os.path.exists(matches_csv):\n",
    "    print(f\"Error: {matches_csv} not found. Run Cell 2 first to scrape matches.\")\n",
    "else:\n",
    "    matches_df = pd.read_csv(matches_csv)\n",
    "    match_ids_to_process = matches_df['match_id'].tolist()\n",
    "    \n",
    "    print(f\"Found {len(match_ids_to_process)} matches to process\")\n",
    "    print(f\"Estimated events: ~{len(match_ids_to_process) * 300} (avg 300 events/game)\")\n",
    "    print(\"\\nStarting extraction...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    all_events = []\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get PUUID for target player\n",
    "    puuid = get_summoner_puuid(SUMMONER_NAME, SUMMONER_TAG)\n",
    "    \n",
    "    if not puuid:\n",
    "        print(\"Error: Could not get PUUID\")\n",
    "    else:\n",
    "        for idx, match_id in enumerate(match_ids_to_process):\n",
    "            try:\n",
    "                # Fetch match data and timeline\n",
    "                match_data = get_match_details(match_id)\n",
    "                if not match_data:\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: No match data\")\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                timeline_data = get_match_timeline(match_id)\n",
    "                if not timeline_data:\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: No timeline data\")\n",
    "                    error_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # Extract all events\n",
    "                events = extract_all_events(match_data, timeline_data, puuid)\n",
    "                all_events.extend(events)\n",
    "                processed_count += 1\n",
    "                \n",
    "                # Progress update every 10 matches\n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    avg_time = elapsed / (idx + 1)\n",
    "                    remaining = avg_time * (len(match_ids_to_process) - idx - 1)\n",
    "                    print(f\"[{idx+1}/{len(match_ids_to_process)}] Processed: {processed_count} | \"\n",
    "                          f\"Events: {len(all_events):,} | \"\n",
    "                          f\"ETA: {int(remaining/60)}m {int(remaining%60)}s\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"[{idx+1}/{len(match_ids_to_process)}] ✗ {match_id}: Error - {str(e)}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "        \n",
    "        # Convert to DataFrame and save\n",
    "        if all_events:\n",
    "            events_df = pd.DataFrame(all_events)\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_path = \"data/nattynatt_rengar_events.csv\"\n",
    "            events_df.to_csv(output_path, index=False)\n",
    "            \n",
    "            elapsed_total = time.time() - start_time\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"EVENT EXTRACTION COMPLETE\")\n",
    "            print(\"=\"*80)\n",
    "            print(f\"Processed matches: {processed_count}/{len(match_ids_to_process)}\")\n",
    "            print(f\"Errors: {error_count}\")\n",
    "            print(f\"Total events extracted: {len(all_events):,}\")\n",
    "            print(f\"Total time: {int(elapsed_total/60)}m {int(elapsed_total%60)}s\")\n",
    "            print(f\"\\nSaved to: {output_path}\")\n",
    "            print(f\"File size: {os.path.getsize(output_path) / (1024*1024):.1f} MB\")\n",
    "            \n",
    "            # Event type breakdown\n",
    "            print(\"\\nEvent type breakdown:\")\n",
    "            event_counts = events_df['event_type'].value_counts()\n",
    "            for event_type, count in event_counts.head(10).items():\n",
    "                print(f\"  - {event_type}: {count:,}\")\n",
    "            \n",
    "            # NattyNatt specific stats\n",
    "            natty_events = events_df[events_df['is_nattynatt'] == True]\n",
    "            print(f\"\\nNattyNatt's events: {len(natty_events):,}\")\n",
    "            if len(natty_events) > 0:\n",
    "                print(f\"  - MONSTER_KILL: {len(natty_events[natty_events['event_type'] == 'MONSTER_KILL']):,}\")\n",
    "                print(f\"  - CHAMPION_KILL: {len(natty_events[natty_events['event_type'] == 'CHAMPION_KILL']):,}\")\n",
    "                print(f\"  - ITEM_PURCHASED: {len(natty_events[natty_events['event_type'] == 'ITEM_PURCHASED']):,}\")\n",
    "                print(f\"  - WARD_PLACED: {len(natty_events[natty_events['event_type'] == 'WARD_PLACED']):,}\")\n",
    "        else:\n",
    "            print(\"\\nNo events extracted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7392a16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE EXTRACTION TEST\n",
      "================================================================================\n",
      "\n",
      "Testing all extraction functions on a single match...\n",
      "\n",
      "✓ Found PUUID: DefvgEBJ...\n",
      "Fetching a test match...\n",
      "  Fetched 100 match IDs (total: 100)\n",
      "Testing with match: KR_7907383471\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. SUMMARY EXTRACTION (Cell 2)\n",
      "   ✓ Extracted 117 summary fields\n",
      "   - Win: True\n",
      "   - KDA: 7/1/6\n",
      "   - Enemy jungle: Elise\n",
      "   - Primary rune: 8000\n",
      "\n",
      "2. FRAME EXTRACTION (Cell 4 - All 10 Players)\n",
      "   ✓ Extracted 170 frame records\n",
      "   - Players tracked: 10\n",
      "   - Minutes covered: 17\n",
      "\n",
      "   Sample (NattyNatt at minute 5):\n",
      "     - Position: (8311, 2426)\n",
      "     - Gold: 1843\n",
      "     - Level: 4\n",
      "     - CS: 32\n",
      "\n",
      "   Enemy Jungler: Elise\n",
      "     - Frames tracked: 17\n",
      "\n",
      "3. EVENT EXTRACTION (Cell 5 - Precise Timestamps)\n",
      "   ✓ Extracted 600 events\n",
      "   - Event types: 17\n",
      "\n",
      "   Top event types:\n",
      "     - ITEM_PURCHASED: 145\n",
      "     - ITEM_DESTROYED: 106\n",
      "     - SKILL_LEVEL_UP: 93\n",
      "     - LEVEL_UP: 81\n",
      "     - WARD_PLACED: 72\n",
      "\n",
      "   NattyNatt's events: 67\n",
      "     - Jungle camps cleared: 0\n",
      "     - Champion kills: 7\n",
      "     - Items purchased: 14\n",
      "\n",
      "================================================================================\n",
      "✓ ALL EXTRACTION FUNCTIONS WORKING CORRECTLY!\n",
      "================================================================================\n",
      "\n",
      "You can now run:\n",
      "  - Cell 2: Re-scrape all matches with comprehensive data\n",
      "  - Cell 4: Extract frame-by-frame data for all players\n",
      "  - Cell 5: Extract all events with precise timestamps\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test All Extraction Functions on Single Match\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE EXTRACTION TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTesting all extraction functions on a single match...\\n\")\n",
    "\n",
    "# Get PUUID\n",
    "puuid = get_summoner_puuid(SUMMONER_NAME, SUMMONER_TAG)\n",
    "\n",
    "if puuid:\n",
    "    # Get a single match\n",
    "    print(\"Fetching a test match...\")\n",
    "    match_ids = get_match_ids(puuid, count=1, queue_id=420, start_time=None)\n",
    "    \n",
    "    if match_ids:\n",
    "        test_match_id = match_ids[0]\n",
    "        print(f\"Testing with match: {test_match_id}\\n\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        # Fetch match data\n",
    "        match_data = get_match_details(test_match_id)\n",
    "        timeline_data = get_match_timeline(test_match_id)\n",
    "        \n",
    "        if match_data and timeline_data:\n",
    "            # Test 1: Summary extraction (existing)\n",
    "            print(\"\\n1. SUMMARY EXTRACTION (Cell 2)\")\n",
    "            match_result = process_match(test_match_id, puuid)\n",
    "            if match_result:\n",
    "                print(f\"   ✓ Extracted {len(match_result)} summary fields\")\n",
    "                print(f\"   - Win: {match_result.get('win')}\")\n",
    "                print(f\"   - KDA: {match_result.get('kills')}/{match_result.get('deaths')}/{match_result.get('assists')}\")\n",
    "                print(f\"   - Enemy jungle: {match_result.get('enemy_jungle')}\")\n",
    "                print(f\"   - Primary rune: {match_result.get('primary_tree')}\")\n",
    "            else:\n",
    "                print(\"   ✗ Not a Rengar game or error\")\n",
    "            \n",
    "            # Test 2: Frame extraction (all players)\n",
    "            print(\"\\n2. FRAME EXTRACTION (Cell 4 - All 10 Players)\")\n",
    "            frames = extract_all_frames_multi_player(match_data, timeline_data, puuid)\n",
    "            print(f\"   ✓ Extracted {len(frames)} frame records\")\n",
    "            print(f\"   - Players tracked: {len(set(f['participant_id'] for f in frames))}\")\n",
    "            print(f\"   - Minutes covered: {len(set(f['minute'] for f in frames))}\")\n",
    "            \n",
    "            # Show sample frame data\n",
    "            natty_frames = [f for f in frames if f['is_nattynatt']]\n",
    "            if natty_frames:\n",
    "                sample_frame = natty_frames[5] if len(natty_frames) > 5 else natty_frames[0]\n",
    "                print(f\"\\n   Sample (NattyNatt at minute {sample_frame['minute']}):\")\n",
    "                print(f\"     - Position: ({sample_frame['position_x']}, {sample_frame['position_y']})\")\n",
    "                print(f\"     - Gold: {sample_frame['total_gold']}\")\n",
    "                print(f\"     - Level: {sample_frame['level']}\")\n",
    "                print(f\"     - CS: {sample_frame['total_cs']}\")\n",
    "            \n",
    "            # Show enemy jungler comparison\n",
    "            enemy_jg_frames = [f for f in frames if f['is_enemy_jungler']]\n",
    "            if enemy_jg_frames:\n",
    "                enemy_champ = enemy_jg_frames[0]['champion']\n",
    "                print(f\"\\n   Enemy Jungler: {enemy_champ}\")\n",
    "                print(f\"     - Frames tracked: {len(enemy_jg_frames)}\")\n",
    "            \n",
    "            # Test 3: Event extraction\n",
    "            print(\"\\n3. EVENT EXTRACTION (Cell 5 - Precise Timestamps)\")\n",
    "            events = extract_all_events(match_data, timeline_data, puuid)\n",
    "            print(f\"   ✓ Extracted {len(events)} events\")\n",
    "            \n",
    "            # Event type breakdown\n",
    "            event_types = {}\n",
    "            for event in events:\n",
    "                et = event['event_type']\n",
    "                event_types[et] = event_types.get(et, 0) + 1\n",
    "            \n",
    "            print(f\"   - Event types: {len(event_types)}\")\n",
    "            print(\"\\n   Top event types:\")\n",
    "            for et, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "                print(f\"     - {et}: {count}\")\n",
    "            \n",
    "            # NattyNatt's events\n",
    "            natty_events = [e for e in events if e['is_nattynatt']]\n",
    "            print(f\"\\n   NattyNatt's events: {len(natty_events)}\")\n",
    "            monster_kills = [e for e in natty_events if e['event_type'] == 'MONSTER_KILL']\n",
    "            print(f\"     - Jungle camps cleared: {len(monster_kills)}\")\n",
    "            if monster_kills:\n",
    "                first_camp = monster_kills[0]\n",
    "                print(f\"     - First camp: {first_camp.get('monster_subtype', 'N/A')} at {first_camp['timestamp']:.1f}s\")\n",
    "            \n",
    "            champion_kills = [e for e in natty_events if e['event_type'] == 'CHAMPION_KILL']\n",
    "            print(f\"     - Champion kills: {len(champion_kills)}\")\n",
    "            \n",
    "            items_purchased = [e for e in natty_events if e['event_type'] == 'ITEM_PURCHASED']\n",
    "            print(f\"     - Items purchased: {len(items_purchased)}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"✓ ALL EXTRACTION FUNCTIONS WORKING CORRECTLY!\")\n",
    "            print(\"=\"*80)\n",
    "            print(\"\\nYou can now run:\")\n",
    "            print(\"  - Cell 2: Re-scrape all matches with comprehensive data\")\n",
    "            print(\"  - Cell 4: Extract frame-by-frame data for all players\")\n",
    "            print(\"  - Cell 5: Extract all events with precise timestamps\")\n",
    "            \n",
    "        else:\n",
    "            print(\"✗ Could not fetch match/timeline data\")\n",
    "    else:\n",
    "        print(\"✗ No matches found\")\n",
    "else:\n",
    "    print(\"✗ Failed to get PUUID\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
